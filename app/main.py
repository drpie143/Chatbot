{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMrxfUwemXrGz8jBtAMMpfn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Yn-3dg8Sr5b7"},"outputs":[],"source":["\n","\n","# --- 1. IMPORT CÁC THƯ VIỆN CẦN THIẾT ---\n","import os\n","import pickle\n","import gzip\n","import re\n","import numpy as np\n","import faiss\n","from fastapi import FastAPI\n","from pydantic import BaseModel\n","from sentence_transformers import SentenceTransformer\n","from rank_bm25 import BM25Okapi\n","import google.generativeai as genai\n","from typing import List, Dict, Any\n","\n","# --- 2. CẤU HÌNH ---\n","# Lấy API Key từ biến môi trường để bảo mật\n","API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n","\n","# Tên model và đường dẫn artifacts bên trong Docker container\n","EMBED_MODEL_NAME = \"AITeamVN/Vietnamese_Embedding\"\n","GENAI_MODEL_NAME = \"gemini-2.5-flash\"\n","ARTIFACTS_DIR = \"/app/artifacts\"\n","\n","FAISS_PATH = f\"{ARTIFACTS_DIR}/index.faiss\"\n","METAS_PATH = f\"{ARTIFACTS_DIR}/metas.pkl.gz\"\n","BM25_PATH = f\"{ARTIFACTS_DIR}/bm25.pkl.gz\"\n","ID_MAP_PATH = f\"{ARTIFACTS_DIR}/id_to_record.pkl\" # File tra cứu nhanh\n","\n","# --- 3. TẢI TÀI NGUYÊN MỘT LẦN KHI KHỞI ĐỘNG ---\n","RAG_RESOURCES = {} # Kho chứa các tài nguyên đã tải\n","\n","def load_resources():\n","    \"\"\"Tải tất cả các model và file index vào bộ nhớ một lần duy nhất.\"\"\"\n","    print(\"Khởi động server: Đang tải các tài nguyên RAG...\")\n","\n","    RAG_RESOURCES[\"embedder\"] = SentenceTransformer(EMBED_MODEL_NAME)\n","    RAG_RESOURCES[\"faiss_index\"] = faiss.read_index(FAISS_PATH)\n","\n","    with gzip.open(METAS_PATH, \"rb\") as f:\n","        RAG_RESOURCES[\"metadatas\"] = pickle.load(f)\n","    with gzip.open(BM25_PATH, \"rb\") as f:\n","        RAG_RESOURCES[\"bm25\"] = pickle.load(f)\n","    with open(ID_MAP_PATH, \"rb\") as f:\n","        RAG_RESOURCES[\"id_map\"] = pickle.load(f)\n","\n","    if not API_KEY:\n","        raise ValueError(\"API Key của Gemini chưa được thiết lập!\")\n","    genai.configure(api_key=API_KEY)\n","    RAG_RESOURCES[\"genai_model\"] = genai.GenerativeModel(GENAI_MODEL_NAME)\n","\n","    print(\"✅ Tải tài nguyên RAG thành công!\")\n","\n","# --- 4. KHỞI TẠO ỨNG DỤNG FASTAPI ---\n","app = FastAPI(title=\"eGovernment Chatbot API\")\n","\n","@app.on_event(\"startup\")\n","async def startup_event():\n","    load_resources()\n","\n","# --- 5. CÁC HÀM LOGIC  ---\n","# Các hàm này được copy và chỉnh sửa một chút để sử dụng tài nguyên đã được tải sẵn trong RAG_RESOURCES thay vì đọc lại từ file mỗi lần gọi.\n","\n","def minmax_scale(arr):\n","    arr = np.array(arr, dtype=\"float32\")\n","    if len(arr) == 0: return arr\n","    mn, mx = float(np.min(arr)), float(np.max(arr))\n","    if mx - mn < 1e-6: return np.ones_like(arr)\n","    return (arr - mn) / (mx - mn)\n","\n","def retrieve(query: str, top_k=10, w_vec=0.7, w_bm25=0.3):\n","    faiss_index = RAG_RESOURCES[\"faiss_index\"]\n","    bm25_loaded = RAG_RESOURCES[\"bm25\"]\n","    embedder = RAG_RESOURCES[\"embedder\"]\n","\n","    qv = embedder.encode([query], normalize_embeddings=True).astype(\"float32\")\n","    D, I = faiss_index.search(qv, top_k * 5)\n","    vec_scores, vec_idx = D[0].tolist(), I[0].tolist()\n","\n","    tokenized_query = query.split()\n","    bm25_scores_all = bm25_loaded.get_scores(tokenized_query)\n","    bm25_top_idx = np.argsort(-bm25_scores_all)[:top_k * 5].tolist()\n","\n","    union_idx = list(dict.fromkeys(vec_idx + bm25_top_idx))\n","    vec_map = {i: s for i, s in zip(vec_idx, vec_scores)}\n","    vec_list = [vec_map.get(i, 0.0) for i in union_idx]\n","    bm25_list = [bm25_scores_all[i] for i in union_idx]\n","\n","    vec_scaled = minmax_scale(vec_list)\n","    bm25_scaled = minmax_scale(bm25_list)\n","    fused = w_vec * vec_scaled + w_bm25 * bm25_scaled\n","    order = np.argsort(-fused)\n","\n","    results = [(union_idx[i], float(fused[i])) for i in order[:top_k]]\n","    return results\n","\n","def get_full_procedure_text_by_id(input_id: str) -> str:\n","    \"\"\"Hàm tra cứu dữ liệu thô SIÊU NHANH từ file id_to_record.pkl\"\"\"\n","    field_map = {\n","        \"ten_thu_tuc\": \"Tên thủ tục\",\n","        \"cach_thuc_thuc_hien\": \"Cách thức thực hiện\",\n","        \"thanh_phan_ho_so\": \"Thành phần hồ sơ\",\n","        \"trinh_tu_thuc_hien\": \"Trình tự thực hiện\",\n","        \"co_quan_thuc_hien\": \"Cơ quan thực hiện\",\n","        \"yeu_cau_dieu_kien\": \"Yêu cầu, điều kiện\",\n","        \"thu_tuc_lien_quan\": \"Thủ tục liên quan\",\n","    }\n","    record = RAG_RESOURCES[\"id_map\"].get(input_id)\n","    if not record:\n","        return \"\"\n","\n","    parts = []\n","    for k, v in record.items():\n","        if v and k in field_map:\n","            parts.append(f\"**{field_map[k]}**:\\n{str(v).strip()}\")\n","    return \"\\n\\n\".join(parts)\n","\n","def get_context_from_results(results: list) -> tuple[str, list]:\n","    \"\"\"Tạo bối cảnh và thu thập nguồn từ kết quả truy hồi.\"\"\"\n","    context = \"\"\n","    sources = set()\n","    metadatas = RAG_RESOURCES[\"metadatas\"]\n","\n","    unique_parent_ids = set()\n","    for res_id, score in results:\n","        parent_id = metadatas[res_id].get(\"parent_id\")\n","        if parent_id and parent_id not in unique_parent_ids:\n","            full_text = get_full_procedure_text_by_id(parent_id)\n","            if full_text:\n","                context += f\"--- TRÍCH ĐOẠN THỦ TỤC LIÊN QUAN ---\\n\"\n","                context += full_text + \"\\n\\n\"\n","                sources.add(parent_id)\n","                unique_parent_ids.add(parent_id)\n","\n","    return context, list(sources)\n","\n","# --- 6. ĐỊNH NGHĨA API MODELS ---\n","class QueryRequest(BaseModel):\n","    question: str\n","\n","class AnswerResponse(BaseModel):\n","    answer: str\n","    sources: List[str]\n","\n","# --- 7. API ENDPOINT CHÍNH ---\n","@app.post(\"/ask\", response_model=AnswerResponse)\n","async def ask_question(request: QueryRequest):\n","    query = request.question\n","\n","    # 1. Truy hồi thông tin (Retrieval)\n","    retrieved_results = retrieve(query, top_k=3)\n","\n","    if not retrieved_results:\n","        return AnswerResponse(answer=\"Xin lỗi, tôi không tìm thấy thông tin nào liên quan đến câu hỏi của bạn.\", sources=[])\n","\n","    # 2. Tạo bối cảnh và lấy nguồn (Augmentation)\n","    context, sources = get_context_from_results(retrieved_results)\n","\n","    # 3. Xây dựng Prompt cuối cùng\n","    prompt = (\n","        \"Bạn là một trợ lý AI chuyên về thủ tục hành chính Việt Nam. \"\n","        \"Trả lời tiếng Việt, chính xác, dựa hoàn toàn vào DỮ LIỆU bao gồm các thủ tục liên quan. \"\n","        \"Trình bày gọn, có gạch đầu dòng nếu phù hợp, và luôn đính kèm các Nguồn (đường link) xuất hiện trong dữ liệu ở cuối.\"\n","        \"Nếu thông tin không đủ, hãy nói rằng bạn không tìm thấy thông tin trong các tài liệu được cung cấp.\\n\\n\"\n","        f\"--- BỐI CẢNH ---\\n{context}\"\n","        f\"--- CÂU HỎI CỦA NGƯỜI DÙNG ---\\n{query}\\n\\n\"\n","        \"--- TRẢ LỜI ---\"\n","    )\n","\n","    # 4. Gọi mô hình Gemini để sinh câu trả lời (Generation)\n","    genai_model = RAG_RESOURCES[\"genai_model\"]\n","    try:\n","        response = genai_model.generate_content(prompt)\n","        final_answer = response.text.strip()\n","    except Exception as e:\n","        raise HTTPException(status_code=500, detail=f\"Lỗi khi gọi mô hình Gemini: {e}\")\n","\n","    return AnswerResponse(answer=final_answer, sources=sources)\n","\n","@app.get(\"/\")\n","def read_root():\n","    return {\"status\": \"eGovernment Chatbot API is running\"}"]}]}